{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6X19hz2BM3a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos\n",
        "df_EmpAttrition = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataSets/empleadosRETO.csv')\n"
      ],
      "metadata": {
        "id": "hWbUULjFjqEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar las columnas especificadas que no tienen relación con la salida\n",
        "columns_to_drop = ['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours', 'PerformanceRating', 'JobLevel']\n",
        "df_EmpAtriClean = df_EmpAttrition.drop(columns=columns_to_drop)\n",
        "\n",
        "# Evaluar las columnas restantes para obtener un resumen estadístico\n",
        "#column_info = df_EmpAtriClean.describe(include='all')\n",
        "#print(column_info)\n"
      ],
      "metadata": {
        "id": "0vDycLlIjP7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la columna 'HiringDate' a un formato de fecha\n",
        "df_EmpAtriClean['HiringDate'] = pd.to_datetime(df_EmpAtriClean['HiringDate'], errors='coerce')\n",
        "\n",
        "invalid_dates = df_EmpAtriClean[df_EmpAtriClean['HiringDate'].isna()]\n",
        "#print(\"Fechas inválidas:\")\n",
        "#print(invalid_dates)\n",
        "\n",
        "df_EmpAtriClean = df_EmpAtriClean.dropna(subset=['HiringDate'])\n",
        "#print(df_EmpAtriClean['HiringDate'].dtype)  # Debe mostrar \"datetime64[ns]\"\n",
        "\n",
        "# Crear la columna 'Year' extrayendo el año de la fecha de contratación\n",
        "df_EmpAtriClean['Year'] = df_EmpAtriClean['HiringDate'].dt.year.astype(int)\n",
        "\n",
        "# Crear la columna 'YearsAtCompany' calculando los años desde la fecha de contratación hasta 2018\n",
        "df_EmpAtriClean['YearsAtCompany'] = 2018 - df_EmpAtriClean['Year']\n",
        "\n",
        "#print(df_EmpAtriClean[['HiringDate', 'Year', 'YearsAtCompany']].head())\n"
      ],
      "metadata": {
        "id": "JuTNfI6Rld_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renombrar la columna 'DistanceFromHome' a 'DistanceFromHome_km'\n",
        "df_EmpAtriClean.rename(columns={'DistanceFromHome': 'DistanceFromHome_km'}, inplace=True)\n",
        "\n",
        "# Crear una nueva columna 'DistanceFromHome' eliminando las letras 'km' y convirtiendo a entero\n",
        "df_EmpAtriClean['DistanceFromHome'] = df_EmpAtriClean['DistanceFromHome_km'].str.replace(' km', '').astype(int)\n",
        "\n",
        "#print(df_EmpAtriClean[['DistanceFromHome_km', 'DistanceFromHome']].head())"
      ],
      "metadata": {
        "id": "aLzDgLtFlKUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar las columnas 'Year', 'HiringDate', y 'DistanceFromHome_km'\n",
        "columns_to_remove = ['Year', 'HiringDate', 'DistanceFromHome_km']\n",
        "df_EmpAtriClean.drop(columns=columns_to_remove, inplace=True)\n",
        "\n",
        "#print(df_EmpAtriClean.head())"
      ],
      "metadata": {
        "id": "T3_Tf_dMozxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el ingreso promedio por departamento\n",
        "df_SueldoPromedioDepto = df_EmpAtriClean.groupby('Department')['MonthlyIncome'].mean().reset_index()\n",
        "\n",
        "# Renombrar la columna con el sueldo promedio\n",
        "df_SueldoPromedioDepto.rename(columns={'MonthlyIncome': 'SueldoPromedio'}, inplace=True)\n",
        "\n",
        "df_SueldoPromedioDepto"
      ],
      "metadata": {
        "id": "KmNf4zkfpYrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalar la variable 'MonthlyIncome'\n",
        "scaler = MinMaxScaler()\n",
        "df_EmpAtriClean['MonthlyIncomeScaled'] = scaler.fit_transform(df_EmpAtriClean[['MonthlyIncome']])\n",
        "\n",
        "#df_EmpAtriClean[['MonthlyIncome', 'MonthlyIncomeScaled']].head()"
      ],
      "metadata": {
        "id": "YWVjt5ddpYn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Convertir la variable 'Attrition' a numérica: 'Yes' -> 1, 'No' -> 0\n",
        "df_EmpAtriClean['Attrition'] = df_EmpAtriClean['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Convertir las otras variables categóricas a numéricas\n",
        "categorical_columns = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus']\n",
        "df_EmpAtriClean = pd.get_dummies(df_EmpAtriClean, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Asegurarse de que todas las columnas son numéricas\n",
        "df_EmpAtriClean = df_EmpAtriClean.apply(pd.to_numeric, errors='coerce')"
      ],
      "metadata": {
        "id": "IOz3Rw8epYkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la correlación entre las variables y 'Attrition'\n",
        "correlation_matrix = df_EmpAtriClean.corr()\n",
        "\n",
        "# Extraer las correlaciones de 'Attrition' con todas las demás variables\n",
        "attrition_correlation = correlation_matrix['Attrition'].sort_values(ascending=False)\n",
        "\n",
        "attrition_correlation"
      ],
      "metadata": {
        "id": "BTkIDcthpYhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar las variables que tienen una correlación mayor o igual a 0.1\n",
        "selected_columns = attrition_correlation[attrition_correlation.abs() >= 0.1].index\n",
        "\n",
        "# Crear el nuevo DataFrame EmpleadosAttritionFinal con las columnas seleccionadas\n",
        "EmpleadosAttritionFinal = df_EmpAtriClean[selected_columns]\n",
        "\n",
        "#EmpleadosAttritionFinal.head()"
      ],
      "metadata": {
        "id": "r-Q_G9GMtfsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar PCA\n",
        "pca = PCA()\n",
        "EmpleadosAttritionPCA = pca.fit_transform(EmpleadosAttritionFinal)\n",
        "\n",
        "EmpleadosAttritionPCA[:5]"
      ],
      "metadata": {
        "id": "AOixD04ztfpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la cantidad de componentes necesarios para explicar el 80% de la varianza\n",
        "explained_variance_ratio = pca.explained_variance_ratio_.cumsum()\n",
        "n_components = (explained_variance_ratio >= 0.80).argmax() + 1\n",
        "\n",
        "# Seleccionar los primeros n_components\n",
        "selected_components = EmpleadosAttritionPCA[:, :n_components]\n",
        "\n",
        "# Crear un DataFrame con los componentes seleccionados\n",
        "component_names = [f'C{i}' for i in range(n_components)]\n",
        "components_df = pd.DataFrame(selected_components, columns=component_names)\n",
        "\n",
        "# Agregar los componentes al DataFrame EmpleadosAttritionFinal\n",
        "EmpleadosAttritionFinal = EmpleadosAttritionFinal.assign(**components_df)\n",
        "\n",
        "EmpleadosAttritionFinal.head()\n",
        "\n",
        "#print(f\"Varianza explicada por cada componente: {explained_variance_ratio}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc1feGuBtfl-",
        "outputId": "ff90e852-1337-4eaa-df55-c7436245935e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Varianza explicada por cada componente: [0.99999448 0.99999746 0.99999913 0.99999968 0.99999985 0.9999999\n",
            " 0.99999995 0.99999998 0.99999998 0.99999999 0.99999999 1.\n",
            " 1.         1.         1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reordenar las columnas\n",
        "columns_order = [col for col in EmpleadosAttritionFinal.columns if col != 'Attrition'] + ['Attrition']\n",
        "EmpleadosAttritionFinal = EmpleadosAttritionFinal[columns_order]\n",
        "\n",
        "EmpleadosAttritionFinal.to_csv('/content/drive/MyDrive/Colab Notebooks/DataSets/EmpleadosAttritionFinal.csv', index=False)"
      ],
      "metadata": {
        "id": "avPe-zbOx6bU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}